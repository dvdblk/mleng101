# Building GPT

basically just [nanoGPT](https://github.com/karpathy/nanoGPT), thanks [Andrej](https://www.youtube.com/watch?v=kCc8FmEb1nY) :)

* [`gpt.ipynb`](gpt.ipynb) commented steps to get
* [`bigram.py`](bigram.py) bigram lm with a full training loop
    * `python bigram.py` downloads 1MB shakespeare data, trains on the gpu if available